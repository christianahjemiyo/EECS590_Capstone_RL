from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Any

import numpy as np


@dataclass
class StepResult:
    state: int
    reward: float
    done: bool
    info: Dict[str, Any]


class MDPSimEnv:
    """Tabular MDP simulator built from the dataset.

    The MDP is generated by scripts/build_mdp.py.
    """

    def __init__(self, mdp_path: str, seed: int = 7, max_steps: int = 30):
        data = np.load(Path(mdp_path))
        self.P = data["P"]
        self.R = data["R"]
        self.n_states = int(self.P.shape[0])
        self.n_actions = int(self.P.shape[1])
        self.rng = np.random.default_rng(seed)
        self.max_steps = max_steps
        self._step_count = 0
        self._state = 0

    def reset(self) -> int:
        self._step_count = 0
        self._state = int(self.rng.integers(0, self.n_states))
        return self._state

    def step(self, action: int) -> StepResult:
        if action < 0 or action >= self.n_actions:
            raise ValueError(f"Invalid action {action}. Expected 0..{self.n_actions - 1}.")

        probs = self.P[self._state, action, :]
        next_state = int(self.rng.choice(self.n_states, p=probs))
        reward = float(self.R[self._state, action, next_state])

        self._step_count += 1
        done = self._step_count >= self.max_steps
        self._state = next_state
        return StepResult(state=next_state, reward=reward, done=done, info={})
